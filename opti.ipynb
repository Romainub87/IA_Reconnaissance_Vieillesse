{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import layers,models\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On importe notre jeu de donnée puis on remplace les valeurs textuelle par des entiers car cela est plus facile à traiter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "data['Class'].replace(['YOUNG','MIDDLE','OLD'],[0,1,2],inplace=True)#inplace true pour juste modifier le dataframe et pas en créer un nouveau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regardons le format de ces donnees\n",
      "\n",
      "          ID  Class\n",
      "0    377.jpg      1\n",
      "1  17814.jpg      0\n",
      "2  21283.jpg      1\n",
      "3  16496.jpg      0\n",
      "4   4487.jpg      1\n"
     ]
    }
   ],
   "source": [
    "print('Regardons le format de ces donnees\\n')\n",
    "print(data.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lireImage(chemin):\n",
    "\timg = tf.io.read_file(chemin)\n",
    "\timg = tf.image.decode_jpeg(img, channels=3) # channel 3 pour une image en couleur\n",
    "\timg = tf.image.convert_image_dtype(img, dtype=tf.float32) # dtype le format de donnée\n",
    "\timg = tf.image.resize(img, (150,150)) # 150 de largeur 150 de longueur\n",
    "\treturn img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charger(chemin, reponse):\n",
    "    img = lireImage(chemin)\n",
    "    return (img, reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "listeChemin = []\n",
    "listeReponse = []\n",
    "for chemin in os.listdir(\"Train\"):\n",
    "    listeChemin.append(\"Train\"+\"/\"+chemin)\n",
    "for i in listeChemin:\n",
    "    tete,queue = os.path.split(i) #Sépare le path dans un tuple tete queue où la queue represente les donnees\n",
    "    reponse = data.loc[data['ID'] == queue]['Class'].values[0] #loc permet de rechercher selon\n",
    "    #une expression booléene donc ici on recherche quand l'ID est égal a la queue à la case Class de notre dataframe et on récupére la valeur \n",
    "    listeReponse.append(reponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tailleEntrainement = int(0.95*(len(listeChemin)))\n",
    "tailleTest = int(0.05*(len(listeChemin)))\n",
    "\n",
    "entrainement = tf.data.Dataset.from_tensor_slices((listeChemin[:tailleEntrainement], listeReponse[:tailleEntrainement]))\n",
    "test = tf.data.Dataset.from_tensor_slices((listeChemin[tailleTest:], listeReponse[tailleTest:]))\n",
    "\n",
    "entrainement = (entrainement\n",
    "    .map(charger, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(64)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "test = (test\n",
    "    .map(charger, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(64)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Conv2D(filters=30, kernel_size=(3, 3), activation='relu', input_shape=(150, 150, 3), padding = 'same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding = 'same'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "296/296 [==============================] - 312s 1s/step - loss: 0.3773 - accuracy: 0.8509 - val_loss: 0.4119 - val_accuracy: 0.8331\n",
      "Epoch 2/10\n",
      "296/296 [==============================] - 310s 1s/step - loss: 0.3077 - accuracy: 0.8796 - val_loss: 0.3976 - val_accuracy: 0.8433\n",
      "Epoch 3/10\n",
      "296/296 [==============================] - 309s 1s/step - loss: 0.2574 - accuracy: 0.8995 - val_loss: 0.3347 - val_accuracy: 0.8700\n",
      "Epoch 4/10\n",
      "296/296 [==============================] - 296s 1s/step - loss: 0.2106 - accuracy: 0.9207 - val_loss: 0.2728 - val_accuracy: 0.9008\n",
      "Epoch 5/10\n",
      "296/296 [==============================] - 291s 983ms/step - loss: 0.1814 - accuracy: 0.9311 - val_loss: 0.2771 - val_accuracy: 0.8982\n",
      "Epoch 6/10\n",
      "296/296 [==============================] - 277s 936ms/step - loss: 0.1488 - accuracy: 0.9448 - val_loss: 0.2913 - val_accuracy: 0.8993\n",
      "Epoch 7/10\n",
      "296/296 [==============================] - 269s 909ms/step - loss: 0.1345 - accuracy: 0.9501 - val_loss: 0.3245 - val_accuracy: 0.8917\n",
      "Epoch 8/10\n",
      "296/296 [==============================] - 269s 909ms/step - loss: 0.1209 - accuracy: 0.9549 - val_loss: 0.1864 - val_accuracy: 0.9454\n",
      "Epoch 9/10\n",
      "296/296 [==============================] - 269s 909ms/step - loss: 0.0946 - accuracy: 0.9659 - val_loss: 0.2125 - val_accuracy: 0.9410\n",
      "Epoch 10/10\n",
      "296/296 [==============================] - 276s 932ms/step - loss: 0.0991 - accuracy: 0.9642 - val_loss: 0.2089 - val_accuracy: 0.9460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157d8192b90>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(entrainement, epochs=10, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296/296 [==============================] - 66s 224ms/step\n",
      "Reponse données par le modèle  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n",
      "Reponse attendu [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "testPred = model.predict(test)\n",
    "resultat = [np.argmax(item) for item in testPred]\n",
    "print(\"Reponse données par le modèle \",resultat[:20])\n",
    "\n",
    "reponseAttendu = listeReponse[tailleTest:]\n",
    "print(\"Reponse attendu\", reponseAttendu[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 103ms/step\n",
      "reponse donnée par le modèle  [0]\n"
     ]
    }
   ],
   "source": [
    "testImagePerso =  tf.data.Dataset.from_tensor_slices((['Test/moi.png'],[0]))\n",
    "testImagePerso = (testImagePerso\n",
    "    .map(charger, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    .batch(64)\n",
    "    .prefetch(tf.data.AUTOTUNE)          \n",
    "    )\n",
    "testPredPerso = model.predict(testImagePerso)\n",
    "resultatTest = [np.argmax(item) for item in testPredPerso]\n",
    "print(\"reponse donnée par le modèle \",resultatTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
